{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "구내식당_식수_인원_예측의 사본",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9HmEl-ADNBK"
      },
      "source": [
        "!pip install pycaret\n",
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlUlKe5yacL1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "np.random.seed(0)\n",
        "\n",
        "from pycaret.regression import *\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from konlpy.tag import Kkma\n",
        "\n",
        "import torch\n",
        "import os, re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCkPAXmhZjR2"
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "train.columns = ['일자', '요일', '정원','휴가자', '출장자', '야근자',\\\n",
        "                 '재택근무자', '조식', '중식', '석식', '중식계', '석식계']\n",
        "test.columns = ['일자', '요일', '정원','휴가자', '출장자', '야근자',\\\n",
        "                 '재택근무자', '조식', '중식', '석식']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le95ZzxcamND"
      },
      "source": [
        "train[['재택근무자', '중식계', '석식계']] = train[['재택근무자', '중식계', '석식계']].astype('int')\n",
        "test['재택근무자'] = test['재택근무자'].astype('int')\n",
        "\n",
        "train['일자'] = pd.to_datetime(train['일자'])\n",
        "test['일자'] = pd.to_datetime(test['일자'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjPQZDCCatss"
      },
      "source": [
        "train['석식계'].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqMSdeePa3f-"
      },
      "source": [
        "train['년'] = train['일자'].dt.year\n",
        "train['월'] = train['일자'].dt.month\n",
        "train['일'] = train['일자'].dt.day\n",
        "train['주'] = train['일자'].dt.week\n",
        "\n",
        "test['년'] = test['일자'].dt.year\n",
        "test['월'] = test['일자'].dt.month\n",
        "test['일'] = test['일자'].dt.day\n",
        "test['주'] = test['일자'].dt.week"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4QXJ_r_vfjj"
      },
      "source": [
        "### 자연어처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq17QDA-lHAj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3_0S3gurN_p"
      },
      "source": [
        "!pip install scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2Xb8KYCb478"
      },
      "source": [
        "stopwords = ['쌀밥', '찰현미밥','현미밥', '흑미밥', '수수밥', '검정콩밥', '차조밥',\n",
        "             '기장밥', '귀리밥', '강낭콩밥', '찰보리밥', '배추김치', '겉절이김치', '깍두기',\n",
        "             '석박지', '봄동겉절이', '양상추샐러드', '잡곡밥', '포기김치', '무침', '쌀']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdI7YqLzR17g"
      },
      "source": [
        "def get_food_embedding(x):\n",
        "    x_ = []\n",
        "    x = x.split(' ')\n",
        "    for i in x:\n",
        "        if '쌀밥' in i or '찰현미밥' in i or '현미밥' in i or '흑미밥' in i or '수수밥' in i or '검정콩밥' in i or '차조밥' in i or '기장밥' in i or '귀리밥' in i or '강낭콩밥' in i or '찰보리밥' in i or '배추김치' in i or '겉절이김치' in i or '깍두기' in i or '잡곡밥' in i or '포기김치' in i:\n",
        "            continue\n",
        "        if '(' in i and ':' in i and ')' in i:\n",
        "            continue\n",
        "        if '/' in i:\n",
        "            x_.extend(i.split('/'))\n",
        "        else:\n",
        "            x_.append(i)\n",
        "    x_ = list(set(x_))\n",
        "    x_.remove('')\n",
        "    return ','.join(x_)\n",
        "\n",
        "train['중식메뉴_split'] = train['중식'].apply(lambda x: get_food_embedding(x))\n",
        "train['석식메뉴_split'] = train['석식'].apply(lambda x: get_food_embedding(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1mClCSXuXRR"
      },
      "source": [
        "test['중식메뉴_split'] = test['중식'].apply(lambda x: get_food_embedding(x))\n",
        "test['석식메뉴_split'] = test['석식'].apply(lambda x: get_food_embedding(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qln_sNOBed2l"
      },
      "source": [
        "train['중식메뉴_split'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_R0e7_flqDj"
      },
      "source": [
        "lunch_lst = []\n",
        "lunch_count = []\n",
        "pref = 0\n",
        "for i in tqdm(range(1205)):\n",
        "  try:\n",
        "    if train['중식계'][i] >= 880:\n",
        "      pref = 1\n",
        "    else:\n",
        "      pref = 0\n",
        "\n",
        "    lunch_lst.append(train['중식메뉴_split'][i])\n",
        "    lunch_count.append(pref)\n",
        "  except:\n",
        "    pass\n",
        "for i in range(len(lunch_lst)):\n",
        "  lunch_lst[i] = lunch_lst[i].replace(',', ' ')\n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_MTb5OQewtB"
      },
      "source": [
        "dinner_lst = []\n",
        "dinner_count = []\n",
        "pref_d = 0\n",
        "for i in tqdm(range(1205)):\n",
        "  try:\n",
        "    if train['석식계'][i] > 476:\n",
        "      pref_d = 1\n",
        "    else:\n",
        "      pref_d = 0\n",
        "\n",
        "    dinner_lst.append(train['석식메뉴_split'][i])\n",
        "    dinner_count.append(pref_d)\n",
        "  except:\n",
        "    pass\n",
        "for i in range(len(dinner_lst)):\n",
        "  dinner_lst[i] = dinner_lst[i].replace(',', ' ')\n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QBjZZjgcIZf"
      },
      "source": [
        "\n",
        "# if '밥' in lunch_lst[0]:\n",
        "#   lunch_lst[0].pop('밥')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th7PGIgmvxzz"
      },
      "source": [
        "lunch_lst_test = []\n",
        "lunch_count_test = []\n",
        "for i in tqdm(range(50)):\n",
        "  try:\n",
        "    lunch_lst_test.append(test['중식메뉴_split'][i])\n",
        "    lunch_count_test.append(0)\n",
        "  except:\n",
        "    pass\n",
        "for i in range(len(lunch_lst_test)):\n",
        "  lunch_lst_test[i] = lunch_lst_test[i].replace(',', ' ')\n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9Ag-Jlle_2A"
      },
      "source": [
        "dinner_lst_test = []\n",
        "dinner_count_test = []\n",
        "for i in tqdm(range(50)):\n",
        "  try:\n",
        "    dinner_lst_test.append(test['석식메뉴_split'][i])\n",
        "    dinner_count_test.append(0)\n",
        "  except:\n",
        "    pass\n",
        "for i in range(len(dinner_lst_test)):\n",
        "  dinner_lst_test[i] = dinner_lst_test[i].replace(',', ' ')\n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--KU3lShoL5e"
      },
      "source": [
        "lunch_df = pd.DataFrame({'중식':lunch_lst, '선호':lunch_count})\n",
        "dinner_df = pd.DataFrame({'석식':dinner_lst, '선호':dinner_count})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy4I5mBEwo1I"
      },
      "source": [
        "lunch_df_t = pd.DataFrame({'중식':lunch_lst_test, '선호':lunch_count_test})\n",
        "dinner_df_t = pd.DataFrame({'석식':dinner_lst_test, '선호':dinner_count_test})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDp3azdvykrW"
      },
      "source": [
        "토크나이저 + 텐서플로우"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYtVnNm_vU6S"
      },
      "source": [
        "stopwords = ['쌀밥', '찰현미밥','현미밥', '흑미밥', '수수밥', '검정콩밥', '차조밥',\n",
        "             '기장밥', '귀리밥', '강낭콩밥', '찰보리밥', '배추김치', '겉절이김치', '깍두기',\n",
        "             '석박지', '봄동겉절이', '양상추샐러드', '잡곡밥', '포기김치', '무침', 'ㄴ', 'ㄹ', 'd', '차', '이', '장', '아', '되',\n",
        "             '맵', '타', '리', '채', '소', '가', ')', '어', '(', '오', '사', '쯔', '순', '실', '커', '프리', '란', '깻', '쫄']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY2TTagmwEao"
      },
      "source": [
        "# from konlpy.tag import Kkma\n",
        "\n",
        "# kkma = Kkma()\n",
        "# X_train = []\n",
        "# for sentence in tqdm(lunch_df['중식']):\n",
        "#   X_train.append([word for word in kkma.morphs(sentence) if not word in stopwords])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm0y6gnUxqkR"
      },
      "source": [
        "# X_test = []\n",
        "# for sentence in lunch_df_t['중식']:\n",
        "#   X_test.append([word for word in kkma.morphs(sentence) if not word in stopwords])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-M_c7DQyOyi"
      },
      "source": [
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# tokenizer = Tokenizer()\n",
        "# tokenizer.fit_on_texts(X_train)\n",
        "# print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnm8Hupe1f6s"
      },
      "source": [
        "# tokenizer = Tokenizer(951, oov_token='OOV')\n",
        "# tokenizer.fit_on_texts(X_train)\n",
        "# X_train = tokenizer.texts_to_sequences(X_train)\n",
        "# X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMaZigan12FC"
      },
      "source": [
        "# y_train = np.array(lunch_df['선호'])\n",
        "# y_test = np.array(lunch_df_t['선호'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjgLpkpr2HGJ"
      },
      "source": [
        "# drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]\n",
        "\n",
        "# X_train = np.delete(X_train, drop_train, axis = 0)\n",
        "# y_train = np.delete(y_train, drop_train, axis = 0)\n",
        "\n",
        "# print(len(X_train))\n",
        "# print(len(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQd0OIDi2doS"
      },
      "source": [
        "# print('메뉴 최대길이', max(len(l) for l in X_train))\n",
        "# print('메뉴 평균길이', sum(map(len, X_train))/len(X_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Acot6Q3Aji"
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.hist([len(s)for s in X_train], bins=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Eflpu5U3aF4"
      },
      "source": [
        "# max_len = 20\n",
        "# X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "# X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDgY9Lm-3k24"
      },
      "source": [
        "# from tensorflow.keras.layers import Embedding, Dense, LSTM, Dropout\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# checkpoint_path = 'my_checkpoint.ckpt'\n",
        "# checkpoint = ModelCheckpoint(checkpoint_path, \n",
        "#                              save_weights_only=True, \n",
        "#                              save_best_only=True, \n",
        "#                              monitor='val_loss',\n",
        "#                              verbose=1)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(951, 100))\n",
        "# model.add(LSTM(128, return_sequences=True))\n",
        "# model.add(LSTM(64))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(16, activation='relu'))\n",
        "# model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss='binary_crossentropy',\n",
        "#               metrics=['acc'])\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0dvchNv4IdY"
      },
      "source": [
        "# history = model.fit(X_train, y_train, epochs = 15, batch_size = 32, callbacks=[checkpoint], validation_split = 0.2)\n",
        "# model.load_weights(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSGczdiB4mSF"
      },
      "source": [
        "# model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n86GkedH4q0h"
      },
      "source": [
        "# hist_dict = history.history\n",
        "# loss = hist_dict['loss']\n",
        "# val_loss = hist_dict['val_loss']\n",
        "# acc = hist_dict['acc']\n",
        "# val_acc = hist_dict['val_acc']\n",
        "# plt.plot(loss, 'b--', label='training loss')\n",
        "# plt.plot(val_loss, 'r:', label='validation loss')\n",
        "# plt.legend()\n",
        "# plt.grid()\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(acc, 'b--', label = 'training acc')\n",
        "# plt.plot(val_acc, 'r:', label='validation acc')\n",
        "# plt.legend()\n",
        "# plt.grid()\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUJRd8uA5eml"
      },
      "source": [
        "# def sentiment_predict(new_sentence):\n",
        "#   new_token = [word for word in kkma.morphs(new_sentence) if not word in stopwords]\n",
        "#   new_sequences = tokenizer.texts_to_sequences([new_token])\n",
        "#   new_pad = pad_sequences(new_sequences, maxlen=max_len)\n",
        "#   score = float(model.predict(new_pad))\n",
        "\n",
        "#   if score > 0.5:\n",
        "#     print(\"{} 선호({:.2f}%)\".format(new_sentence, score*100))\n",
        "#   else:\n",
        "#     print(\"{} 부정({:.2f}%)\".format(new_sentence, (1-score)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTT6_YiM6biI"
      },
      "source": [
        "# sentiment_predict('요구르트 계란찜 쇠불고기 오징어찌개 잡곡밥 청포묵무침 포기김치 쌀밥')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipcbn_Gt4LtI"
      },
      "source": [
        "그리드서치 회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E4Ojv6Ptanw"
      },
      "source": [
        "from konlpy.tag import Kkma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_QtZgx6tjKh"
      },
      "source": [
        "kkma = Kkma()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-IYSzD3rAVi"
      },
      "source": [
        "def tok(text):\n",
        "  t = kkma.nouns(text)\n",
        "  return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cYj5_S9pWV3"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "vect = TfidfVectorizer(tokenizer = tok, ngram_range = (1,2), min_df = 3, max_df = 0.9)\n",
        "vect.fit(lunch_df['중식'])\n",
        "vect_matrix_train = vect.transform(lunch_df['중식'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8d1QJ6dfZe-"
      },
      "source": [
        "vect_d = TfidfVectorizer(tokenizer = tok, ngram_range = (1,2), min_df = 3, max_df = 0.9)\n",
        "vect_d.fit(dinner_df['석식'])\n",
        "vect_d_matrix_train = vect_d.transform(dinner_df['석식'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsQN0CpvT7UD"
      },
      "source": [
        "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(vect_matrix_train, lunch_df['선호'], test_size = 0.2, random_state = 42)\n",
        "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(vect_d_matrix_train, dinner_df['선호'], test_size = 0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukibvoi2p9iz"
      },
      "source": [
        "lg_clf = LGBMClassifier(n_estimators = 10000, n_jobs=4, max_depth=6, learning_rate=0.0005, num_leaves=2^8-1)\n",
        "lg_clf_d = LGBMClassifier(n_estimators = 10000, n_jobs=4, max_depth=8, learning_rate=0.0003, num_leaves=2^7-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySdNewd9UrlP"
      },
      "source": [
        "evals_l = [(X_test_l, y_test_l)]\n",
        "evals_d = [(X_test_d, y_test_d)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9cm4eS1tWfh"
      },
      "source": [
        "lg_clf.fit(X_train_l, y_train_l, early_stopping_rounds = 1000, eval_metric = 'logloss',\n",
        "           eval_set = evals_l, verbose = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAtbweEUWHty"
      },
      "source": [
        "lg_clf_d.fit(X_train_d, y_train_d, early_stopping_rounds = 500, eval_metric = 'logloss',\n",
        "           eval_set = evals_d, verbose = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNdCaxf7vr_v"
      },
      "source": [
        "vect_matrix_test = vect.transform(lunch_df_t['중식'])\n",
        "preds = lg_clf.predict(vect_matrix_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJa_qraXfwuX"
      },
      "source": [
        "vect_d_matrix_test = vect_d.transform(dinner_df_t['석식'])\n",
        "preds_d = lg_clf_d.predict(vect_d_matrix_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e83v5U_viPp"
      },
      "source": [
        "lunch_df_t['선호'] = preds\n",
        "dinner_df_t['선호'] = preds_d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lXdmEnFYG3X"
      },
      "source": [
        "lunch_df_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx-6tSexcgFv"
      },
      "source": [
        "train['중식선호도'] = lunch_count\n",
        "test['중식선호도'] = lunch_count_test\n",
        "train['석식선호도'] = dinner_count\n",
        "test['석식선호도'] = dinner_count_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XQzFUBqqm74"
      },
      "source": [
        "train['요일'] = train['일자'].dt.weekday\n",
        "train['야근_가능'] = train['요일'].apply(lambda x : 1 if (x==2) or (x==4) else 0)\n",
        "train['출근인원'] = train['정원']-(train['휴가자']+train['출장자']+train['재택근무자'])\n",
        "train['휴가비율'] = train['휴가자']/train['정원']\n",
        "train['출장비율'] = train['출장자']/train['정원']\n",
        "train['야근비율'] = train['야근자']/train['출근인원']\n",
        "train['재택비율'] = train['재택근무자']/train['정원']\n",
        "\n",
        "test['요일'] = test['일자'].dt.weekday\n",
        "test['야근_가능'] = test['요일'].apply(lambda x : 1 if (x==2) or (x==4) else 0)\n",
        "test['출근인원'] = test['정원']-(test['휴가자']+test['출장자']+test['재택근무자'])\n",
        "test['휴가비율'] = test['휴가자']/test['정원']\n",
        "test['출장비율'] = test['출장자']/test['정원']\n",
        "test['야근비율'] = test['야근자']/test['출근인원']\n",
        "test['재택비율'] = test['재택근무자']/test['정원']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJRsBJJ0RH2U"
      },
      "source": [
        "**정규화 BUT 휴가 전 후 고려하면 X**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BECuT_mbHgNo"
      },
      "source": [
        "from scipy import stats\n",
        "train['z'] = stats.zscore(train['휴가자'])\n",
        "train['zscale'] = stats.zscore(train['석식계'])\n",
        "train['zscale_c'] = stats.zscore(train['출장비율'])\n",
        "train['zscale_y'] = stats.zscore(train['야근비율'])\n",
        "\n",
        "train = train[train['zscale'].between(-1.96, 1.96)]\n",
        "train = train[train['zscale_c'].between(-1.96, 1.96)]\n",
        "train = train[train['zscale_y'].between(-1.96, 1.96)]\n",
        "train = train[train['z'].between(-1.96, 1.96)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhiMFVyaGPQI"
      },
      "source": [
        "a = train.groupby(train['출장비율'])['석식계'].mean()\n",
        "a.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw-cuHg9nhCJ"
      },
      "source": [
        "train = train.drop(columns=['z', 'zscale', 'zscale_c', 'zscale_y', '중식메뉴_split', '석식메뉴_split'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GKv9xViu5e3"
      },
      "source": [
        "rain_2016 = pd.read_csv('충무공동_강수_201602_201612.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLWW2G2uvg14"
      },
      "source": [
        "rain_2016.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCP7eJNJvCi4"
      },
      "source": [
        "rain_2016[(rain_2016['hour'] == 1100) & (rain_2016['value location:81_75 Start : 20160201 '] > 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG1A3DInulrv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yajBqX3tqv14"
      },
      "source": [
        "train_1 = train[['일자', '요일', '월', '년', '휴가자', '휴가비율', '출장비율','중식선호도', '중식계','출근인원']]\n",
        "train_2 = train[['일자', '요일', '월', '년', '휴가자', '출근인원', '야근_가능','석식선호도', '휴가비율','출장비율', '야근비율', '석식계']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMG81-Zd0EpL"
      },
      "source": [
        "reg = setup(data=train_1,\n",
        "            target='중식계',\n",
        "            numeric_imputation = 'mean',\n",
        "            normalize = True,\n",
        "            silent= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-TH5M-G0Es9"
      },
      "source": [
        "compare_models()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VwACtYG0FIi"
      },
      "source": [
        "best_5 = compare_models(sort='MAE', n_select=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI6Gu_sIHccA"
      },
      "source": [
        "blended = blend_models(estimator_list= best_5, fold=5, optimize='MAE')\n",
        "pred_holdout = predict_model(blended)\n",
        "final_model = finalize_model(blended)\n",
        "pred1 = predict_model(final_model, test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IgMrp_JH13n"
      },
      "source": [
        "submission = pd.read_csv('sample_submission.csv')\n",
        "submission['중식계'] = pred1['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtJ9FqQeHmjL"
      },
      "source": [
        "reg = setup(data=train_2,\n",
        "            target='석식계',\n",
        "            numeric_imputation = 'mean',\n",
        "            normalize = True,\n",
        "            silent= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnwX1aVR0FMg"
      },
      "source": [
        "compare_models()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ8eorUIIF8R"
      },
      "source": [
        "best_5 = compare_models(sort = 'MAE', n_select = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1ifzzKbIF3d"
      },
      "source": [
        "blended = blend_models(estimator_list = best_5, fold = 5, optimize = 'MAE')\n",
        "pred_holdout = predict_model(blended)\n",
        "final_model = finalize_model(blended)\n",
        "pred2 = predict_model(final_model, test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1MmS-pBmOMK"
      },
      "source": [
        "pred2['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StAqyP5rIFzy"
      },
      "source": [
        "submission['석식계'] = pred2['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDbZYkrdIFvi"
      },
      "source": [
        "submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y0iJ7GHIFie"
      },
      "source": [
        "submission.to_csv('sub_4968_3099_lightgbm선호도처리2.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}